{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02090f9f-f987-4ef7-9e79-20b8ec368da5",
   "metadata": {},
   "source": [
    "# Retrain - Data Preparation\n",
    "\n",
    "1. Fit feature encoders to the whole training (train+valid) dataset and transform training (train+valid split)/test dataset\n",
    "2. Retrain final model on the transformed training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180ebf7b-206c-4911-b6ef-cf3ceac67b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=pd.errors.PerformanceWarning)   # For convinience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21af3771-66e9-47ea-b10e-755064ab0db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364464</td>\n",
       "      <td>0.401162</td>\n",
       "      <td>0.26847</td>\n",
       "      <td>0.46226</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>0.366788</td>\n",
       "      <td>0.359249</td>\n",
       "      <td>0.345247</td>\n",
       "      <td>0.726792</td>\n",
       "      <td>5142.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381515</td>\n",
       "      <td>0.363768</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.40455</td>\n",
       "      <td>0.47225</td>\n",
       "      <td>0.334828</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.342239</td>\n",
       "      <td>0.382931</td>\n",
       "      <td>1132.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169481</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>0.381055</td>\n",
       "      <td>4442.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169482</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183243</td>\n",
       "      <td>0.251696</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.21374</td>\n",
       "      <td>0.19431</td>\n",
       "      <td>0.167024</td>\n",
       "      <td>0.165648</td>\n",
       "      <td>0.404520</td>\n",
       "      <td>0.734887</td>\n",
       "      <td>1734.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169483</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.50420</td>\n",
       "      <td>0.54983</td>\n",
       "      <td>0.453334</td>\n",
       "      <td>0.462286</td>\n",
       "      <td>0.312885</td>\n",
       "      <td>0.258702</td>\n",
       "      <td>4876.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169484</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392395</td>\n",
       "      <td>0.322536</td>\n",
       "      <td>0.36636</td>\n",
       "      <td>0.29095</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.307628</td>\n",
       "      <td>0.301921</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.387270</td>\n",
       "      <td>773.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169485</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935935</td>\n",
       "      <td>0.646164</td>\n",
       "      <td>0.96114</td>\n",
       "      <td>0.96909</td>\n",
       "      <td>0.83814</td>\n",
       "      <td>0.644013</td>\n",
       "      <td>0.908179</td>\n",
       "      <td>0.869135</td>\n",
       "      <td>0.807657</td>\n",
       "      <td>9470.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169486 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10  ...     cont6  \\\n",
       "0         A    B    A    B    A    A    A    A    B     A  ...  0.718367   \n",
       "1         A    B    A    A    A    A    A    A    B     B  ...  0.438917   \n",
       "2         A    B    A    B    A    A    A    A    B     B  ...  0.178193   \n",
       "3         A    B    A    A    A    A    A    A    B     A  ...  0.364464   \n",
       "4         A    A    A    A    B    A    A    A    A     A  ...  0.381515   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...       ...   \n",
       "169481    A    B    A    A    A    B    A    A    B     A  ...  0.212308   \n",
       "169482    A    B    A    A    A    A    A    B    B     A  ...  0.183243   \n",
       "169483    A    B    A    A    B    A    A    A    B     A  ...  0.460158   \n",
       "169484    A    B    A    A    A    A    A    A    B     A  ...  0.392395   \n",
       "169485    A    B    A    A    B    A    A    A    B     B  ...  0.935935   \n",
       "\n",
       "           cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0       0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "1       0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "2       0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "3       0.401162  0.26847  0.46226  0.50556  0.366788  0.359249  0.345247   \n",
       "4       0.363768  0.24564  0.40455  0.47225  0.334828  0.352251  0.342239   \n",
       "...          ...      ...      ...      ...       ...       ...       ...   \n",
       "169481  0.325779  0.29758  0.34365  0.30529  0.245410  0.241676  0.258586   \n",
       "169482  0.251696  0.40028  0.21374  0.19431  0.167024  0.165648  0.404520   \n",
       "169483  0.521362  0.29758  0.50420  0.54983  0.453334  0.462286  0.312885   \n",
       "169484  0.322536  0.36636  0.29095  0.43919  0.307628  0.301921  0.731059   \n",
       "169485  0.646164  0.96114  0.96909  0.83814  0.644013  0.908179  0.869135   \n",
       "\n",
       "          cont14     loss  \n",
       "0       0.714843  2213.18  \n",
       "1       0.304496  1283.60  \n",
       "2       0.432606  2763.85  \n",
       "3       0.726792  5142.87  \n",
       "4       0.382931  1132.22  \n",
       "...          ...      ...  \n",
       "169481  0.381055  4442.25  \n",
       "169482  0.734887  1734.24  \n",
       "169483  0.258702  4876.80  \n",
       "169484  0.387270   773.93  \n",
       "169485  0.807657  9470.07  \n",
       "\n",
       "[169486 rows x 131 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv('../data/processed/cleaned_train.csv')\n",
    "valid_df = pd.read_csv('../data/processed/cleaned_valid.csv')\n",
    "test_df = pd.read_csv('../data/processed/test_split.csv')\n",
    "k_test_df = pd.read_csv('../data/raw/test.csv') # kaggle test set\n",
    "\n",
    "# Combine train and valid into full training set\n",
    "full_train_df = pd.concat([train_df, valid_df], ignore_index=True)\n",
    "full_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5d1600-e596-47f8-a904-e6c847484a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = [var for var in full_train_df.columns if var.startswith('cat')]\n",
    "cont_vars = [var for var in full_train_df.columns if var.startswith('cont')]\n",
    "\n",
    "# Summarize all categorical columns\n",
    "full_summary_cat_df = pd.DataFrame({\n",
    "    \"n_cats\": full_train_df[cat_vars].nunique(),\n",
    "    \"most_freq_cat\": full_train_df[cat_vars].agg(lambda x: x.value_counts().idxmax()),\n",
    "    \"most_freq_count\": full_train_df[cat_vars].agg(lambda x: x.value_counts().max())\n",
    "})\n",
    "\n",
    "#full_summary_cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94208ac2-14b0-486e-9782-ced5f577364e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (169486, 479)\n",
      "Test shape  :  (18831, 479)\n",
      "Kaggle Test shape  :  (125546, 479)\n"
     ]
    }
   ],
   "source": [
    "# Fequency encoding\n",
    "for cat in cat_vars:\n",
    "    \n",
    "    count = full_train_df[cat].value_counts()\n",
    "    \n",
    "    full_train_df[f'{cat}_freq'] = full_train_df[cat].map(count)\n",
    "    full_train_df[f'{cat}_log_freq'] = np.log1p(full_train_df[f'{cat}_freq'])     # take log to compress extreme counts\n",
    "    full_train_df[f'{cat}_norm_freq'] = full_train_df[f'{cat}_freq'] / len(full_train_df)\n",
    "\n",
    "    test_df[f'{cat}_freq'] = test_df[cat].map(count).fillna(0)\n",
    "    test_df[f'{cat}_log_freq'] = np.log1p(test_df[f'{cat}_freq'])     # take log to compress extreme counts\n",
    "    test_df[f'{cat}_norm_freq'] = test_df[f'{cat}_freq'] / len(full_train_df)\n",
    "\n",
    "    k_test_df[f'{cat}_freq'] = k_test_df[cat].map(count).fillna(0)\n",
    "    k_test_df[f'{cat}_log_freq'] = np.log1p(k_test_df[f'{cat}_freq'])     # take log to compress extreme counts\n",
    "    k_test_df[f'{cat}_norm_freq'] = k_test_df[f'{cat}_freq'] / len(full_train_df)\n",
    "\n",
    "print('Train shape : ', full_train_df.shape)\n",
    "print('Test shape  : ', test_df.shape)\n",
    "print('Kaggle Test shape  : ', k_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4b46db-314b-4228-bd31-a2391fa654fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (169486, 479)\n",
      "Test shape  :  (18831, 479)\n",
      "Kaggle Test shape  :  (125546, 479)\n"
     ]
    }
   ],
   "source": [
    "# Ordinal Encoding (Much easier to handle unseen data)\n",
    "ord_en = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "ord_en.fit(full_train_df[cat_vars])\n",
    "    \n",
    "full_train_df[cat_vars] = ord_en.transform(full_train_df[cat_vars])\n",
    "test_df[cat_vars] = ord_en.transform(test_df[cat_vars])\n",
    "k_test_df[cat_vars] = ord_en.transform(k_test_df[cat_vars])\n",
    "\n",
    "print('Train shape : ', full_train_df.shape)\n",
    "print('Test shape  : ', test_df.shape)\n",
    "print('Kaggle Test shape  : ', k_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32571d15-0772-4623-90d2-836ec5cfa406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (169486, 635)\n",
      "Test shape  :  (18831, 635)\n",
      "Kaggle Test shape  :  (125546, 635)\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "# Only on low cardinality columns\n",
    "low_card_cols = full_summary_cat_df[full_summary_cat_df['n_cats'] <= 3].index.to_list()\n",
    "\n",
    "onehot_en = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "onehot_en.fit(full_train_df[low_card_cols])\n",
    "\n",
    "train_onehot_encoded = onehot_en.transform(full_train_df[low_card_cols])\n",
    "test_onehot_encoded = onehot_en.transform(test_df[low_card_cols])\n",
    "k_test_onehot_encoded = onehot_en.transform(k_test_df[low_card_cols])\n",
    "\n",
    "train_onehot_df = pd.DataFrame(train_onehot_encoded, columns=onehot_en.get_feature_names_out(low_card_cols))\n",
    "test_onehot_df = pd.DataFrame(test_onehot_encoded, columns=onehot_en.get_feature_names_out(low_card_cols))\n",
    "k_test_onehot_df = pd.DataFrame(k_test_onehot_encoded, columns=onehot_en.get_feature_names_out(low_card_cols))\n",
    "\n",
    "full_train_df = pd.concat([full_train_df, train_onehot_df], axis=1)\n",
    "test_df = pd.concat([test_df, test_onehot_df], axis=1)\n",
    "k_test_df = pd.concat([k_test_df, k_test_onehot_df], axis=1)\n",
    "\n",
    "print('Train shape : ', full_train_df.shape)\n",
    "print('Test shape  : ', test_df.shape)\n",
    "print('Kaggle Test shape  : ', k_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd77dd5-89a4-4887-b485-37f5e20dc218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (169486, 5507)\n",
      "Test shape  :  (18831, 5507)\n",
      "Kaggle Test shape  :  (125546, 5507)\n"
     ]
    }
   ],
   "source": [
    "# Categorical groups numeric stats\n",
    "for cat in cat_vars:\n",
    "    group = full_train_df.groupby(cat)\n",
    "    for cont in cont_vars:\n",
    "        # Calculate global stats for unseen categories\n",
    "        global_mean = full_train_df[cont].mean()\n",
    "        global_med = full_train_df[cont].median()\n",
    "        global_std = full_train_df[cont].std()\n",
    "        \n",
    "        full_train_df[f'{cat}_{cont}_mean'] = full_train_df[cat].map(group[cont].mean())\n",
    "        test_df[f'{cat}_{cont}_mean'] = test_df[cat].map(group[cont].mean()).fillna(global_mean)\n",
    "        k_test_df[f'{cat}_{cont}_mean'] = k_test_df[cat].map(group[cont].mean()).fillna(global_mean)\n",
    "\n",
    "        full_train_df[f'{cat}_{cont}_med'] = full_train_df[cat].map(group[cont].median())\n",
    "        test_df[f'{cat}_{cont}_med'] = test_df[cat].map(group[cont].median()).fillna(global_med)\n",
    "        k_test_df[f'{cat}_{cont}_med'] = k_test_df[cat].map(group[cont].median()).fillna(global_med)\n",
    "\n",
    "        full_train_df[f'{cat}_{cont}_std'] = full_train_df[cat].map(group[cont].std())\n",
    "        test_df[f'{cat}_{cont}_std'] = test_df[cat].map(group[cont].std()).fillna(global_std)\n",
    "        k_test_df[f'{cat}_{cont}_std'] = k_test_df[cat].map(group[cont].std()).fillna(global_std)\n",
    "\n",
    "print('Train shape : ', full_train_df.shape)\n",
    "print('Test shape  : ', test_df.shape)\n",
    "print('Kaggle Test shape  : ', k_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08155c92-42a7-4c08-9b97-5ff1ce68f9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (169486, 5550)\n",
      "Test shape  :  (18831, 5550)\n",
      "Kaggle Test shape  :  (125546, 5549)\n"
     ]
    }
   ],
   "source": [
    "# Numerics transformation\n",
    "\n",
    "# Rank encoding for numerics\n",
    "def fit_rank_transform(df, col):\n",
    "    unique = sorted(df[col].unique())\n",
    "    ranks = np.searchsorted(unique, unique) / len(unique)\n",
    "    return unique, ranks\n",
    "\n",
    "def transform_rank(values, unique, ranks):\n",
    "    ''' Return the rank of value given the fitted rank transform (unique, ranks) '''\n",
    "    return np.interp(values, unique, ranks)\n",
    "\n",
    "# Winsorization (cap extremes)\n",
    "def fit_winsor(df, col):\n",
    "    l, u = df[col].quantile([0.01, 0.99])\n",
    "    return l, u\n",
    "\n",
    "\n",
    "for cont in cont_vars:\n",
    "    # Log transform\n",
    "    full_train_df[f'log_{cont}'] = np.log1p(full_train_df[cont])\n",
    "    test_df[f'log_{cont}'] = np.log1p(test_df[cont])\n",
    "    k_test_df[f'log_{cont}'] = np.log1p(k_test_df[cont])\n",
    "\n",
    "    # Rank transform\n",
    "    uniq, ranks = fit_rank_transform(full_train_df, cont)\n",
    "    full_train_df[f'{cont}_rank'] = transform_rank(full_train_df[cont], uniq, ranks)\n",
    "    test_df[f'{cont}_rank'] = transform_rank(test_df[cont], uniq, ranks)\n",
    "    k_test_df[f'{cont}_rank'] = transform_rank(k_test_df[cont], uniq, ranks)\n",
    "\n",
    "    # Winsorization\n",
    "    l, u = fit_winsor(full_train_df, cont)\n",
    "    full_train_df[f'{cont}_cap'] = full_train_df[cont].clip(l, u)\n",
    "    test_df[f'{cont}_cap'] = test_df[cont].clip(l, u)\n",
    "    k_test_df[f'{cont}_cap'] = k_test_df[cont].clip(l, u)\n",
    "\n",
    "# Transform target loss\n",
    "full_train_df[f'log_loss'] = np.log(full_train_df['loss'])\n",
    "test_df[f'log_loss'] = np.log(test_df['loss'])\n",
    "\n",
    "print('Train shape : ', full_train_df.shape)\n",
    "print('Test shape  : ', test_df.shape)\n",
    "print('Kaggle Test shape  : ', k_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "272d5d92-ccae-4ee8-827f-bb8af001bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export transformed retrain data\n",
    "full_train_df.to_parquet('../data/retrain/final_transformed_train.parquet', index=False)\n",
    "test_df.to_parquet('../data/retrain/final_transformed_test.parquet', index=False)\n",
    "k_test_df.to_parquet('../data/retrain/final_k_test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee931d3d-1be8-4de8-81d7-9e799859e4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Allstate Claims",
   "language": "python",
   "name": "allstate_claims_severity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
